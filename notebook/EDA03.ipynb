{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 1: Cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/teleCust1000t.csv')  # Reemplazar con la ruta de tu dataset\n",
    "print(\"Dimensiones del dataset:\", df.shape)\n",
    "print(\"\\nInformación del dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 2: Resumen estadístico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 3: Verificar valores faltantes y duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values = df.isnull().sum()\n",
    "print(\"\\nValores faltantes por columna:\")\n",
    "print(missing_values)\n",
    "\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"\\nRegistros duplicados: {duplicates}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 4: Distribución de la variable objetivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "class_dist = df['custcat'].value_counts()\n",
    "sns.barplot(x=class_dist.index, y=class_dist.values)\n",
    "plt.title('Distribución de Categorías de Clientes')\n",
    "plt.xlabel('Categoría')\n",
    "plt.ylabel('Cantidad')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nPorcentaje por categoría:\")\n",
    "print((class_dist / len(df) * 100).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 5: Análisis de variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['tenure', 'age', 'income', 'ed', 'employ', 'address', 'reside']\n",
    "for col in numeric_cols:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Histograma\n",
    "    sns.histplot(data=df, x=col, hue='custcat', kde=True, ax=ax1)\n",
    "    ax1.set_title(f'Distribución de {col}')\n",
    "\n",
    "    # Boxplot\n",
    "    sns.boxplot(data=df, x='custcat', y=col, ax=ax2)\n",
    "    ax2.set_title(f'Boxplot de {col} por Categoría')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 6: Análisis de variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['region', 'marital', 'gender']\n",
    "for col in cat_cols:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    crosstab = pd.crosstab(df[col], df['custcat'], normalize='index') * 100\n",
    "    crosstab.plot(kind='bar', stacked=True)\n",
    "    plt.title(f'Distribución de Categorías por {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Porcentaje')\n",
    "    plt.legend(title='Categoría')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 7: Matriz de correlación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Matriz de Correlación')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 8: Feature Engineering\n",
    ">\n",
    "Crear nuevas variables derivadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['income_per_family'] = df['income'] / (df['reside'] + 1)\n",
    "df['tenure_to_age_ratio'] = df['tenure'] / df['age']\n",
    "df['income_per_education'] = df['income'] / df['ed']\n",
    "\n",
    "# Segmentación\n",
    "df['age_segment'] = pd.qcut(df['age'], q=5, labels=['Very Young', 'Young', 'Middle', 'Senior', 'Very Senior'])\n",
    "df['income_segment'] = pd.qcut(df['income'], q=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "df['tenure_segment'] = pd.qcut(df['tenure'], q=5, labels=['New', 'Recent', 'Established', 'Loyal', 'Very Loyal'])\n",
    "\n",
    "# Interacciones\n",
    "df['income_tenure_interaction'] = df['income'] * df['tenure']\n",
    "df['age_income_ratio'] = df['age'] / df['income']\n",
    "\n",
    "# Validación visual de las nuevas características\n",
    "new_features = ['income_per_family', 'tenure_to_age_ratio', 'income_per_education',\n",
    "                'income_tenure_interaction', 'age_income_ratio']\n",
    "for col in new_features:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(data=df, x='custcat', y=col)\n",
    "    plt.title(f'Distribución de {col} por Categoría')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 9: Escalado de variables numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "numeric_cols_to_scale = ['tenure', 'age', 'income', 'address', 'ed', 'employ', 'reside']\n",
    "df[numeric_cols_to_scale] = scaler.fit_transform(df[numeric_cols_to_scale])\n",
    "\n",
    "print(\"\\nDataset procesado listo para modelado:\")\n",
    "print(df.head())\n",
    "\n",
    "# Guardar el DataFrame procesado\n",
    "df.to_csv('../data/proc_escalado.csv', index=False)\n",
    "print(\"\\nDataFrame procesado guardado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 10: Modelado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos...\n",
      "\n",
      "Preparando datos con características mejoradas...\n",
      "\n",
      "Dimensiones de los datos:\n",
      "X_train: (900, 40)\n",
      "X_test: (200, 40)\n",
      "y_train: (900,)\n",
      "y_test: (200,)\n",
      "Entrenando XGBoost con parámetros mejorados...\n",
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n",
      "\n",
      "Mejores parámetros:\n",
      "{'colsample_bytree': 0.9, 'learning_rate': 0.01, 'max_depth': 6, 'min_child_weight': 1, 'n_estimators': 400, 'subsample': 0.8}\n",
      "Precisión en validación: 0.4467\n",
      "Precisión en test: 0.4050\n",
      "\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Clase 1       0.40      0.36      0.38        53\n",
      "     Clase 2       0.36      0.39      0.37        44\n",
      "     Clase 3       0.45      0.46      0.46        56\n",
      "     Clase 4       0.40      0.40      0.40        47\n",
      "\n",
      "    accuracy                           0.41       200\n",
      "   macro avg       0.40      0.40      0.40       200\n",
      "weighted avg       0.40      0.41      0.40       200\n",
      "\n",
      "\n",
      "Matriz de confusión:\n",
      "[[19 11 15  8]\n",
      " [ 8 17  9 10]\n",
      " [14  6 26 10]\n",
      " [ 7 13  8 19]]\n",
      "\n",
      "Top 15 características más importantes:\n",
      "                                          feature  importance\n",
      "4                                              ed    0.056240\n",
      "19                          tenure_to_age_ratio^2    0.044772\n",
      "35                            age_income_ratio ed    0.036719\n",
      "28                        income_per_education ed    0.034611\n",
      "29                    income_per_education tenure    0.032841\n",
      "23                         tenure_to_age_ratio ed    0.028976\n",
      "21  tenure_to_age_ratio income_tenure_interaction    0.027904\n",
      "27          income_per_education age_income_ratio    0.027344\n",
      "24                     tenure_to_age_ratio tenure    0.026862\n",
      "30                    income_tenure_interaction^2    0.025474\n",
      "6                                          retire    0.025381\n",
      "9                             tenure_to_age_ratio    0.025235\n",
      "25                         income_per_education^2    0.025129\n",
      "22           tenure_to_age_ratio age_income_ratio    0.024989\n",
      "36                        age_income_ratio tenure    0.024731\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "def create_polynomial_features(X, degree=2):\n",
    "    # Seleccionar solo las características numéricas más importantes\n",
    "    important_features = ['tenure_to_age_ratio', 'income_per_education',\n",
    "                         'income_tenure_interaction', 'age_income_ratio',\n",
    "                         'ed', 'tenure']\n",
    "\n",
    "    # Crear características polinómicas\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    poly_features = poly.fit_transform(X[important_features])\n",
    "\n",
    "    # Crear DataFrame con los nuevos nombres\n",
    "    feature_names = poly.get_feature_names_out(important_features)\n",
    "    poly_df = pd.DataFrame(poly_features, columns=feature_names)\n",
    "\n",
    "    # Combinar con características originales\n",
    "    X_new = X.copy()\n",
    "    for col in poly_df.columns:\n",
    "        if col not in X.columns:\n",
    "            X_new[col] = poly_df[col]\n",
    "\n",
    "    return X_new\n",
    "\n",
    "def prepare_data():\n",
    "    # Cargar datos\n",
    "    df = pd.read_csv('../data/proc_escalado.csv')\n",
    "    X = df.drop(['custcat'], axis=1).values\n",
    "    y = df['custcat'].values - 1  # Ajustar etiquetas para empezar desde 0\n",
    "\n",
    "    # División de datos\n",
    "    X_train_temp, X_test, y_train_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_temp, y_train_temp, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Estandarización\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Crear datasets\n",
    "    train_dataset = CustomDataset(X_train, y_train)\n",
    "    val_dataset = CustomDataset(X_val, y_val)\n",
    "    test_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "    return train_dataset, val_dataset, test_dataset, X_train.shape[1]\n",
    "\n",
    "def train_xgboost(X_train, X_test, y_train, y_test):\n",
    "    # Parámetros más extensos para XGBoost\n",
    "    param_grid = {\n",
    "        'n_estimators': [200, 300, 400],\n",
    "        'max_depth': [4, 5, 6],\n",
    "        'learning_rate': [0.01, 0.05, 0.1],\n",
    "        'subsample': [0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "        'min_child_weight': [1, 3, 5]\n",
    "    }\n",
    "\n",
    "    # Crear y entrenar modelo\n",
    "    model = XGBClassifier(random_state=42)\n",
    "    grid = GridSearchCV(\n",
    "        model,\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        scoring='accuracy',\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"Entrenando XGBoost con parámetros mejorados...\")\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    # Imprimir resultados\n",
    "    print(\"\\nMejores parámetros:\")\n",
    "    print(grid.best_params_)\n",
    "    print(f\"Precisión en validación: {grid.best_score_:.4f}\")\n",
    "    print(f\"Precisión en test: {grid.score(X_test, y_test):.4f}\")\n",
    "\n",
    "    # Evaluar en conjunto de prueba\n",
    "    y_pred = grid.predict(X_test)\n",
    "    print(\"\\nReporte de clasificación:\")\n",
    "    print(classification_report(y_test, y_pred,\n",
    "                              target_names=['Clase 1', 'Clase 2', 'Clase 3', 'Clase 4']))\n",
    "\n",
    "    # Matriz de confusión\n",
    "    print(\"\\nMatriz de confusión:\")\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    print(conf_matrix)\n",
    "\n",
    "    # Importancia de características\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': grid.best_estimator_.feature_importances_\n",
    "    })\n",
    "    feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "    print(\"\\nTop 15 características más importantes:\")\n",
    "    print(feature_importance.head(15))\n",
    "\n",
    "    return grid.best_estimator_, feature_importance\n",
    "\n",
    "def main():\n",
    "    print(\"Cargando datos...\")\n",
    "    df = pd.read_csv('../data/proc_escalado.csv')\n",
    "\n",
    "    print(\"\\nPreparando datos con características mejoradas...\")\n",
    "    X_train, X_test, y_train, y_test = prepare_data(df)\n",
    "\n",
    "    print(\"\\nDimensiones de los datos:\")\n",
    "    print(f\"X_train: {X_train.shape}\")\n",
    "    print(f\"X_test: {X_test.shape}\")\n",
    "    print(f\"y_train: {y_train.shape}\")\n",
    "    print(f\"y_test: {y_test.shape}\")\n",
    "\n",
    "    # Entrenar modelo mejorado\n",
    "    best_model, feature_importance = train_xgboost(X_train, X_test, y_train, y_test)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11 Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:29:21,864] A new study created in memory with name: no-name-e74f57ab-53a3-4058-a933-96254686093a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando y preparando datos...\n",
      "Dimensiones del dataset: (1000, 19)\n",
      "Iniciando optimización con Optuna...\n",
      "WARNING:tensorflow:From c:\\Users\\Administrator\\Desktop\\telecom_customer\\ML-Refuerzo-Freddy\\venv\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-05 20:29:55,957] Trial 0 finished with value: 0.2810000002384186 and parameters: {'num_blocks': 26, 'units': 193, 'learning_rate': 3.7920210661803664e-05, 'dropout_rate': 0.49757440993932467, 'decay_rate': 0.9464806346408275}. Best is trial 0 with value: 0.2810000002384186.\n",
      "[I 2024-12-05 20:30:17,882] Trial 1 finished with value: 0.23699999749660491 and parameters: {'num_blocks': 10, 'units': 289, 'learning_rate': 1.2014718671334378e-05, 'dropout_rate': 0.4320407262126319, 'decay_rate': 0.9688970220979977}. Best is trial 0 with value: 0.2810000002384186.\n",
      "[I 2024-12-05 20:30:44,942] Trial 2 finished with value: 0.4 and parameters: {'num_blocks': 14, 'units': 233, 'learning_rate': 6.280677374431575e-05, 'dropout_rate': 0.17540532997230446, 'decay_rate': 0.9592186338416457}. Best is trial 2 with value: 0.4.\n",
      "[I 2024-12-05 20:31:12,012] Trial 3 finished with value: 0.2539999961853027 and parameters: {'num_blocks': 13, 'units': 406, 'learning_rate': 2.7654590982977944e-05, 'dropout_rate': 0.3104910994121872, 'decay_rate': 0.9792914511945295}. Best is trial 2 with value: 0.4.\n",
      "[I 2024-12-05 20:31:50,748] Trial 4 finished with value: 0.23599999845027925 and parameters: {'num_blocks': 24, 'units': 297, 'learning_rate': 2.8071082806570472e-05, 'dropout_rate': 0.3678756926827902, 'decay_rate': 0.9527846998464965}. Best is trial 2 with value: 0.4.\n",
      "[I 2024-12-05 20:32:38,944] Trial 5 finished with value: 0.3400000035762787 and parameters: {'num_blocks': 15, 'units': 468, 'learning_rate': 0.0001304841731453709, 'dropout_rate': 0.3006325686300877, 'decay_rate': 0.9465462967365925}. Best is trial 2 with value: 0.4.\n",
      "[I 2024-12-05 20:33:09,988] Trial 6 finished with value: 0.2510000020265579 and parameters: {'num_blocks': 23, 'units': 155, 'learning_rate': 0.0002908629634560264, 'dropout_rate': 0.4850660352102113, 'decay_rate': 0.9151096011081856}. Best is trial 2 with value: 0.4.\n",
      "[I 2024-12-05 20:33:53,797] Trial 7 finished with value: 0.4099999964237213 and parameters: {'num_blocks': 13, 'units': 333, 'learning_rate': 1.474702780885048e-05, 'dropout_rate': 0.14088924640096745, 'decay_rate': 0.9837828202233598}. Best is trial 7 with value: 0.4099999964237213.\n",
      "[I 2024-12-05 20:35:44,008] Trial 8 finished with value: 0.3599999964237213 and parameters: {'num_blocks': 30, 'units': 194, 'learning_rate': 0.00014295734133865152, 'dropout_rate': 0.12063440805258754, 'decay_rate': 0.9514990791243955}. Best is trial 7 with value: 0.4099999964237213.\n",
      "[I 2024-12-05 20:36:20,117] Trial 9 finished with value: 0.31500000357627866 and parameters: {'num_blocks': 13, 'units': 290, 'learning_rate': 0.0003789896070441448, 'dropout_rate': 0.3642813720790826, 'decay_rate': 0.9210722592213614}. Best is trial 7 with value: 0.4099999964237213.\n",
      "[I 2024-12-05 20:37:08,351] Trial 10 finished with value: 0.2930000007152557 and parameters: {'num_blocks': 18, 'units': 367, 'learning_rate': 1.0037444904721873e-05, 'dropout_rate': 0.20883406432811757, 'decay_rate': 0.9871016330980174}. Best is trial 7 with value: 0.4099999964237213.\n",
      "[I 2024-12-05 20:38:07,476] Trial 11 finished with value: 0.38600000739097595 and parameters: {'num_blocks': 17, 'units': 230, 'learning_rate': 6.218373420602109e-05, 'dropout_rate': 0.10091115583350288, 'decay_rate': 0.964365433451757}. Best is trial 7 with value: 0.4099999964237213.\n",
      "[I 2024-12-05 20:38:41,416] Trial 12 finished with value: 0.42699999213218687 and parameters: {'num_blocks': 10, 'units': 367, 'learning_rate': 0.0007156130687295023, 'dropout_rate': 0.19456910822046786, 'decay_rate': 0.9286680780436325}. Best is trial 12 with value: 0.42699999213218687.\n",
      "[I 2024-12-05 20:39:12,722] Trial 13 finished with value: 0.41200000047683716 and parameters: {'num_blocks': 10, 'units': 378, 'learning_rate': 0.0009088434603127649, 'dropout_rate': 0.2138703449403529, 'decay_rate': 0.9290880157629123}. Best is trial 12 with value: 0.42699999213218687.\n",
      "[I 2024-12-05 20:39:43,330] Trial 14 finished with value: 0.425 and parameters: {'num_blocks': 10, 'units': 439, 'learning_rate': 0.0009872989231872208, 'dropout_rate': 0.22892316063688012, 'decay_rate': 0.9302720424014161}. Best is trial 12 with value: 0.42699999213218687.\n",
      "[I 2024-12-05 20:40:38,510] Trial 15 finished with value: 0.3220000028610229 and parameters: {'num_blocks': 20, 'units': 487, 'learning_rate': 0.000906986593451989, 'dropout_rate': 0.24165252888306057, 'decay_rate': 0.9014247955081014}. Best is trial 12 with value: 0.42699999213218687.\n",
      "[I 2024-12-05 20:41:16,895] Trial 16 finished with value: 0.4180000007152557 and parameters: {'num_blocks': 10, 'units': 430, 'learning_rate': 0.0004932706480941002, 'dropout_rate': 0.25607847089963076, 'decay_rate': 0.9339879928679967}. Best is trial 12 with value: 0.42699999213218687.\n",
      "[I 2024-12-05 20:42:11,501] Trial 17 finished with value: 0.3369999945163727 and parameters: {'num_blocks': 18, 'units': 443, 'learning_rate': 0.00026430836833915886, 'dropout_rate': 0.17354976576557396, 'decay_rate': 0.9087987640886849}. Best is trial 12 with value: 0.42699999213218687.\n",
      "[I 2024-12-05 20:43:01,724] Trial 18 finished with value: 0.30899999737739564 and parameters: {'num_blocks': 16, 'units': 502, 'learning_rate': 0.0006259979837656938, 'dropout_rate': 0.2620814061425012, 'decay_rate': 0.935041957979872}. Best is trial 12 with value: 0.42699999213218687.\n",
      "[I 2024-12-05 20:43:52,090] Trial 19 finished with value: 0.33700000047683715 and parameters: {'num_blocks': 21, 'units': 359, 'learning_rate': 0.00017920351321374162, 'dropout_rate': 0.34753786947870796, 'decay_rate': 0.9212402264625444}. Best is trial 12 with value: 0.42699999213218687.\n",
      "[I 2024-12-05 20:44:27,164] Trial 20 finished with value: 0.42200000286102296 and parameters: {'num_blocks': 12, 'units': 399, 'learning_rate': 0.0005725492249352003, 'dropout_rate': 0.16633845416987267, 'decay_rate': 0.9359796235323182}. Best is trial 12 with value: 0.42699999213218687.\n",
      "[I 2024-12-05 20:45:13,818] Trial 21 finished with value: 0.4289999961853027 and parameters: {'num_blocks': 12, 'units': 410, 'learning_rate': 0.0006168313137037307, 'dropout_rate': 0.18547321324034707, 'decay_rate': 0.9345948618650001}. Best is trial 21 with value: 0.4289999961853027.\n",
      "[I 2024-12-05 20:45:49,003] Trial 22 finished with value: 0.33999999761581423 and parameters: {'num_blocks': 11, 'units': 436, 'learning_rate': 0.0008614098135641734, 'dropout_rate': 0.2134250118854436, 'decay_rate': 0.9261408357533226}. Best is trial 21 with value: 0.4289999961853027.\n",
      "[I 2024-12-05 20:46:22,326] Trial 23 finished with value: 0.4309999942779541 and parameters: {'num_blocks': 12, 'units': 336, 'learning_rate': 0.0004390895803084745, 'dropout_rate': 0.27443719278985723, 'decay_rate': 0.9358488081306254}. Best is trial 23 with value: 0.4309999942779541.\n",
      "[I 2024-12-05 20:47:03,193] Trial 24 finished with value: 0.4199999988079071 and parameters: {'num_blocks': 12, 'units': 333, 'learning_rate': 0.0002415686509299316, 'dropout_rate': 0.27832149229874903, 'decay_rate': 0.9389939144949131}. Best is trial 23 with value: 0.4309999942779541.\n",
      "[I 2024-12-05 20:47:43,066] Trial 25 finished with value: 0.3469999969005585 and parameters: {'num_blocks': 16, 'units': 322, 'learning_rate': 0.00045928021050902206, 'dropout_rate': 0.329321469375502, 'decay_rate': 0.9136072501020944}. Best is trial 23 with value: 0.4309999942779541.\n",
      "[I 2024-12-05 20:48:35,894] Trial 26 finished with value: 0.375 and parameters: {'num_blocks': 15, 'units': 398, 'learning_rate': 0.0003552381848645692, 'dropout_rate': 0.1879450628576555, 'decay_rate': 0.9437440567553658}. Best is trial 23 with value: 0.4309999942779541.\n",
      "[I 2024-12-05 20:49:08,545] Trial 27 finished with value: 0.4370000004768372 and parameters: {'num_blocks': 12, 'units': 257, 'learning_rate': 0.0006528431150438731, 'dropout_rate': 0.1455544089912334, 'decay_rate': 0.921523759071739}. Best is trial 27 with value: 0.4370000004768372.\n",
      "[I 2024-12-05 20:49:46,376] Trial 28 finished with value: 0.4189999997615814 and parameters: {'num_blocks': 14, 'units': 262, 'learning_rate': 0.00018101655723782288, 'dropout_rate': 0.1454185481217443, 'decay_rate': 0.920491317935397}. Best is trial 27 with value: 0.4370000004768372.\n",
      "[I 2024-12-05 20:50:46,828] Trial 29 finished with value: 0.2700000047683716 and parameters: {'num_blocks': 27, 'units': 253, 'learning_rate': 7.633700224223426e-05, 'dropout_rate': 0.40651987822085733, 'decay_rate': 0.9447480009381783}. Best is trial 27 with value: 0.4370000004768372.\n",
      "[I 2024-12-05 20:51:11,809] Trial 30 finished with value: 0.4340000033378601 and parameters: {'num_blocks': 12, 'units': 179, 'learning_rate': 0.00042647794805488376, 'dropout_rate': 0.1487219976208976, 'decay_rate': 0.9039826798169055}. Best is trial 27 with value: 0.4370000004768372.\n",
      "[I 2024-12-05 20:51:34,055] Trial 31 finished with value: 0.4580000102519989 and parameters: {'num_blocks': 12, 'units': 169, 'learning_rate': 0.0003940859018814171, 'dropout_rate': 0.1449904896261067, 'decay_rate': 0.9023037412450531}. Best is trial 31 with value: 0.4580000102519989.\n",
      "[I 2024-12-05 20:51:57,994] Trial 32 finished with value: 0.4580000042915344 and parameters: {'num_blocks': 12, 'units': 129, 'learning_rate': 0.0003663665332478269, 'dropout_rate': 0.13992088909228728, 'decay_rate': 0.9044617823288338}. Best is trial 31 with value: 0.4580000102519989.\n",
      "[I 2024-12-05 20:52:28,196] Trial 33 finished with value: 0.4499999940395355 and parameters: {'num_blocks': 15, 'units': 130, 'learning_rate': 0.0003235899142179185, 'dropout_rate': 0.13964371237433454, 'decay_rate': 0.9012082895690824}. Best is trial 31 with value: 0.4580000102519989.\n",
      "[I 2024-12-05 20:52:57,787] Trial 34 finished with value: 0.4600000023841858 and parameters: {'num_blocks': 15, 'units': 130, 'learning_rate': 0.0003265189981364676, 'dropout_rate': 0.10487449478857133, 'decay_rate': 0.9071788082281335}. Best is trial 34 with value: 0.4600000023841858.\n",
      "[I 2024-12-05 20:53:23,512] Trial 35 finished with value: 0.45 and parameters: {'num_blocks': 14, 'units': 145, 'learning_rate': 0.00021138050547533273, 'dropout_rate': 0.1021568040704059, 'decay_rate': 0.9078356624218585}. Best is trial 34 with value: 0.4600000023841858.\n",
      "[I 2024-12-05 20:53:50,635] Trial 36 finished with value: 0.46599999666213987 and parameters: {'num_blocks': 14, 'units': 135, 'learning_rate': 0.00023973697573604274, 'dropout_rate': 0.10073826764345815, 'decay_rate': 0.9106855586085454}. Best is trial 36 with value: 0.46599999666213987.\n",
      "[I 2024-12-05 20:54:26,908] Trial 37 finished with value: 0.4470000028610229 and parameters: {'num_blocks': 18, 'units': 176, 'learning_rate': 0.00010779433491530503, 'dropout_rate': 0.12225677332550108, 'decay_rate': 0.9124484321325187}. Best is trial 36 with value: 0.46599999666213987.\n",
      "[I 2024-12-05 20:54:55,061] Trial 38 finished with value: 0.4389999985694885 and parameters: {'num_blocks': 14, 'units': 204, 'learning_rate': 0.00016636711071498333, 'dropout_rate': 0.11460295885730443, 'decay_rate': 0.9069160363214515}. Best is trial 36 with value: 0.46599999666213987.\n",
      "[I 2024-12-05 20:55:31,057] Trial 39 finished with value: 0.4290000021457672 and parameters: {'num_blocks': 16, 'units': 165, 'learning_rate': 0.0002871202439094282, 'dropout_rate': 0.15918793810344756, 'decay_rate': 0.9156911755018393}. Best is trial 36 with value: 0.46599999666213987.\n",
      "[I 2024-12-05 20:56:08,389] Trial 40 finished with value: 0.41100000143051146 and parameters: {'num_blocks': 19, 'units': 130, 'learning_rate': 0.0001109094683357082, 'dropout_rate': 0.1256857341452872, 'decay_rate': 0.911188802106554}. Best is trial 36 with value: 0.46599999666213987.\n",
      "[I 2024-12-05 20:56:32,522] Trial 41 finished with value: 0.44899999499320986 and parameters: {'num_blocks': 14, 'units': 151, 'learning_rate': 0.00021959030935036068, 'dropout_rate': 0.10391183907486162, 'decay_rate': 0.905856521744758}. Best is trial 36 with value: 0.46599999666213987.\n",
      "[I 2024-12-05 20:57:00,658] Trial 42 finished with value: 0.4329999923706055 and parameters: {'num_blocks': 14, 'units': 146, 'learning_rate': 0.0002116300031300607, 'dropout_rate': 0.12658645736000854, 'decay_rate': 0.9009140757816383}. Best is trial 36 with value: 0.46599999666213987.\n",
      "[I 2024-12-05 20:57:23,571] Trial 43 finished with value: 0.4289999961853027 and parameters: {'num_blocks': 11, 'units': 198, 'learning_rate': 0.000326239513032569, 'dropout_rate': 0.10446803993437767, 'decay_rate': 0.917571209013282}. Best is trial 36 with value: 0.46599999666213987.\n",
      "[I 2024-12-05 20:57:50,803] Trial 44 finished with value: 0.4550000011920929 and parameters: {'num_blocks': 13, 'units': 210, 'learning_rate': 0.000140956698926911, 'dropout_rate': 0.13175160328977653, 'decay_rate': 0.909751897052891}. Best is trial 36 with value: 0.46599999666213987.\n",
      "[I 2024-12-05 20:58:13,915] Trial 45 finished with value: 0.23599999845027925 and parameters: {'num_blocks': 13, 'units': 216, 'learning_rate': 8.028709165069204e-05, 'dropout_rate': 0.4935369549600596, 'decay_rate': 0.9098447843160548}. Best is trial 36 with value: 0.46599999666213987.\n",
      "[I 2024-12-05 20:58:36,275] Trial 46 finished with value: 0.44699999690055847 and parameters: {'num_blocks': 11, 'units': 169, 'learning_rate': 0.0001438493213191912, 'dropout_rate': 0.15994362207518315, 'decay_rate': 0.9737473023700918}. Best is trial 36 with value: 0.46599999666213987.\n",
      "[I 2024-12-05 23:39:17,366] Trial 47 finished with value: 0.40900000333786013 and parameters: {'num_blocks': 15, 'units': 128, 'learning_rate': 5.448384359879019e-05, 'dropout_rate': 0.13066878125038522, 'decay_rate': 0.904695127531013}. Best is trial 36 with value: 0.46599999666213987.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mejores hiperparámetros encontrados:\n",
      "{'num_blocks': 14, 'units': 135, 'learning_rate': 0.00023973697573604274, 'dropout_rate': 0.10073826764345815, 'decay_rate': 0.9106855586085454}\n",
      "Mejor precisión: 0.4660\n",
      "\n",
      "Entrenando modelo final con los mejores hiperparámetros...\n",
      "Epoch 1/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 65ms/step - accuracy: 0.3081 - loss: 1.9846 - val_accuracy: 0.2350 - val_loss: 4.8512\n",
      "Epoch 2/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.3573 - loss: 1.5562 - val_accuracy: 0.3850 - val_loss: 1.5289\n",
      "Epoch 3/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 0.3669 - loss: 1.4572 - val_accuracy: 0.3700 - val_loss: 1.4357\n",
      "Epoch 4/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.3722 - loss: 1.4503 - val_accuracy: 0.4350 - val_loss: 1.3045\n",
      "Epoch 5/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 0.3892 - loss: 1.3432 - val_accuracy: 0.4150 - val_loss: 1.3036\n",
      "Epoch 6/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.3931 - loss: 1.2970 - val_accuracy: 0.4200 - val_loss: 1.3234\n",
      "Epoch 7/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4140 - loss: 1.3275 - val_accuracy: 0.3750 - val_loss: 1.3034\n",
      "Epoch 8/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.3854 - loss: 1.2720 - val_accuracy: 0.3900 - val_loss: 1.3155\n",
      "Epoch 9/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4233 - loss: 1.2654 - val_accuracy: 0.4050 - val_loss: 1.3053\n",
      "Epoch 10/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4105 - loss: 1.2890 - val_accuracy: 0.4200 - val_loss: 1.3067\n",
      "Epoch 11/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4216 - loss: 1.2741 - val_accuracy: 0.4050 - val_loss: 1.3080\n",
      "Epoch 12/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3929 - loss: 1.3053 - val_accuracy: 0.3950 - val_loss: 1.3049\n",
      "Epoch 13/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4199 - loss: 1.2471 - val_accuracy: 0.3900 - val_loss: 1.3306\n",
      "Epoch 14/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4045 - loss: 1.2099 - val_accuracy: 0.3750 - val_loss: 1.3107\n",
      "Epoch 15/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4552 - loss: 1.2329 - val_accuracy: 0.3900 - val_loss: 1.3115\n",
      "Epoch 16/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4045 - loss: 1.2853 - val_accuracy: 0.3900 - val_loss: 1.2953\n",
      "Epoch 17/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4730 - loss: 1.2658 - val_accuracy: 0.3850 - val_loss: 1.2949\n",
      "Epoch 18/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4404 - loss: 1.2142 - val_accuracy: 0.4050 - val_loss: 1.2819\n",
      "Epoch 19/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.3859 - loss: 1.2472 - val_accuracy: 0.3950 - val_loss: 1.3040\n",
      "Epoch 20/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.4349 - loss: 1.2130 - val_accuracy: 0.3900 - val_loss: 1.3001\n",
      "Epoch 21/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.4260 - loss: 1.2424 - val_accuracy: 0.4000 - val_loss: 1.3069\n",
      "Epoch 22/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4676 - loss: 1.1605 - val_accuracy: 0.4000 - val_loss: 1.2968\n",
      "Epoch 23/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4510 - loss: 1.1887 - val_accuracy: 0.3950 - val_loss: 1.2868\n",
      "Epoch 24/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.4683 - loss: 1.1986 - val_accuracy: 0.3700 - val_loss: 1.2977\n",
      "Epoch 25/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4317 - loss: 1.2122 - val_accuracy: 0.3750 - val_loss: 1.2970\n",
      "Epoch 26/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4782 - loss: 1.1635 - val_accuracy: 0.3550 - val_loss: 1.3321\n",
      "Epoch 27/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.4757 - loss: 1.1825 - val_accuracy: 0.3700 - val_loss: 1.3245\n",
      "Epoch 28/100\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5049 - loss: 1.1036 - val_accuracy: 0.3950 - val_loss: 1.3008\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4023 - loss: 1.3230 \n",
      "\n",
      "Precisión final en conjunto de prueba: 0.4050\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import optuna\n",
    "\n",
    "# 1. Carga y preprocesamiento de datos\n",
    "def prepare_data():\n",
    "    # Cargar el dataset\n",
    "    df = pd.read_csv('../data/proc_escalado.csv')\n",
    "\n",
    "    # Variables categóricas a codificar\n",
    "    categorical_cols = ['region', 'marital', 'gender', 'age_segment',\n",
    "                       'income_segment', 'tenure_segment']\n",
    "\n",
    "    # Codificar variables categóricas\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        label_encoders[col] = LabelEncoder()\n",
    "        df[col] = label_encoders[col].fit_transform(df[col])\n",
    "\n",
    "    # Separar características y variable objetivo\n",
    "    X = df.drop('custcat', axis=1)\n",
    "    y = df['custcat'].values - 1  # Ajustar etiquetas para empezar desde 0\n",
    "\n",
    "    # Escalar características numéricas\n",
    "    numeric_cols = ['tenure', 'age', 'income', 'ed', 'employ', 'address', 'reside',\n",
    "                   'income_per_family', 'tenure_to_age_ratio', 'income_per_education',\n",
    "                   'income_tenure_interaction', 'age_income_ratio']\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# 2. Definición del modelo con bloques residuales\n",
    "class ResidualBlock(layers.Layer):\n",
    "    def __init__(self, units, dropout_rate):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.dense1 = layers.Dense(units, activation='relu')\n",
    "        self.dropout1 = layers.Dropout(dropout_rate)\n",
    "        self.dense2 = layers.Dense(units, activation='relu')\n",
    "        self.dropout2 = layers.Dropout(dropout_rate)\n",
    "        self.add = layers.Add()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        # Asegurar que las dimensiones coincidan para la conexión residual\n",
    "        if inputs.shape[-1] != x.shape[-1]:\n",
    "            inputs = layers.Dense(x.shape[-1])(inputs)\n",
    "\n",
    "        return self.add([x, inputs])\n",
    "\n",
    "def create_model(num_blocks, units, dropout_rate, learning_rate, input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Dense(units)(inputs)\n",
    "\n",
    "    for _ in range(num_blocks):\n",
    "        x = ResidualBlock(units, dropout_rate)(x)\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    outputs = layers.Dense(4, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# 3. Función objetivo para Optuna\n",
    "def objective(trial):\n",
    "    # Hiperparámetros a optimizar\n",
    "    num_blocks = trial.suggest_int('num_blocks', 10, 30)\n",
    "    units = trial.suggest_int('units', 128, 512)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-3, log=True)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
    "    decay_rate = trial.suggest_float('decay_rate', 0.9, 0.99)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "        learning_rate, decay_steps=1000, decay_rate=decay_rate\n",
    "    )\n",
    "\n",
    "    # Callbacks\n",
    "    early_stopping = keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "\n",
    "    # Crear modelo\n",
    "    model = create_model(\n",
    "        num_blocks=num_blocks,\n",
    "        units=units,\n",
    "        dropout_rate=dropout_rate,\n",
    "        learning_rate=lr_schedule,\n",
    "        input_shape=(X.shape[1],)\n",
    "    )\n",
    "\n",
    "    # Cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "\n",
    "    for train_index, val_index in skf.split(X, y):\n",
    "        X_train_fold = X.iloc[train_index].values\n",
    "        X_val_fold = X.iloc[val_index].values\n",
    "        y_train_fold = y[train_index]\n",
    "        y_val_fold = y[val_index]\n",
    "\n",
    "        history = model.fit(\n",
    "            X_train_fold, y_train_fold,\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            validation_data=(X_val_fold, y_val_fold),\n",
    "            callbacks=[early_stopping],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        cv_scores.append(max(history.history['val_accuracy']))\n",
    "\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "# 4. Ejecución principal\n",
    "if __name__ == \"__main__\":\n",
    "    # Preparar datos\n",
    "    print(\"Cargando y preparando datos...\")\n",
    "    X, y = prepare_data()\n",
    "    print(f\"Dimensiones del dataset: {X.shape}\")\n",
    "\n",
    "    # Configurar y ejecutar la optimización\n",
    "    print(\"Iniciando optimización con Optuna...\")\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=100, timeout=7200)  # 2 horas máximo\n",
    "\n",
    "    # Imprimir resultados\n",
    "    print(\"\\nMejores hiperparámetros encontrados:\")\n",
    "    print(study.best_params)\n",
    "    print(f\"Mejor precisión: {study.best_value:.4f}\")\n",
    "\n",
    "    # Entrenar modelo final con los mejores hiperparámetros\n",
    "    print(\"\\nEntrenando modelo final con los mejores hiperparámetros...\")\n",
    "    final_model = create_model(\n",
    "        num_blocks=study.best_params['num_blocks'],\n",
    "        units=study.best_params['units'],\n",
    "        dropout_rate=study.best_params['dropout_rate'],\n",
    "        learning_rate=study.best_params['learning_rate'],\n",
    "        input_shape=(X.shape[1],)\n",
    "    )\n",
    "\n",
    "    # Dividir datos para evaluación final\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Entrenar modelo final\n",
    "    final_model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)]\n",
    "    )\n",
    "\n",
    "    # Evaluar modelo final\n",
    "    test_loss, test_accuracy = final_model.evaluate(X_test, y_test)\n",
    "    print(f\"\\nPrecisión final en conjunto de prueba: {test_accuracy:.4f}\")\n",
    "\n",
    "    # Guardar modelo\n",
    "    final_model.save('final_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 09:39:40,275] A new study created in memory with name: no-name-76531741-cb49-4b79-bc43-9f402191a044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando y preparando datos...\n",
      "Dimensiones del dataset: (1000, 20)\n",
      "Iniciando optimización con Optuna...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-06 09:42:13,709] Trial 0 finished with value: 0.3812499940395355 and parameters: {'batch_size': 128, 'learning_rate': 0.00016176427878897555, 'n_layers': 2, 'dropout': 0.1099035639810079, 'units': 483}. Best is trial 0 with value: 0.3812499940395355.\n",
      "[I 2024-12-06 09:42:25,545] Trial 1 finished with value: 0.3187499940395355 and parameters: {'batch_size': 64, 'learning_rate': 0.00018252338271454872, 'n_layers': 4, 'dropout': 0.3904442410997403, 'units': 335}. Best is trial 0 with value: 0.3812499940395355.\n",
      "[I 2024-12-06 09:42:33,761] Trial 2 finished with value: 0.375 and parameters: {'batch_size': 128, 'learning_rate': 0.00886271435173204, 'n_layers': 2, 'dropout': 0.26752506633539785, 'units': 105}. Best is trial 0 with value: 0.3812499940395355.\n",
      "[I 2024-12-06 09:42:44,952] Trial 3 finished with value: 0.3687500059604645 and parameters: {'batch_size': 128, 'learning_rate': 0.006619927547314162, 'n_layers': 2, 'dropout': 0.10577952380999173, 'units': 474}. Best is trial 0 with value: 0.3812499940395355.\n",
      "[I 2024-12-06 09:42:57,878] Trial 4 finished with value: 0.28125 and parameters: {'batch_size': 128, 'learning_rate': 1.1181737397266638e-05, 'n_layers': 5, 'dropout': 0.12077615768659458, 'units': 144}. Best is trial 0 with value: 0.3812499940395355.\n",
      "[I 2024-12-06 09:43:08,736] Trial 5 finished with value: 0.3499999940395355 and parameters: {'batch_size': 64, 'learning_rate': 0.00018766041313534893, 'n_layers': 5, 'dropout': 0.13102490670085168, 'units': 400}. Best is trial 0 with value: 0.3812499940395355.\n",
      "[I 2024-12-06 09:43:30,040] Trial 6 finished with value: 0.35624998807907104 and parameters: {'batch_size': 16, 'learning_rate': 0.000900795091227546, 'n_layers': 3, 'dropout': 0.440196262126455, 'units': 255}. Best is trial 0 with value: 0.3812499940395355.\n",
      "[I 2024-12-06 09:43:40,324] Trial 7 finished with value: 0.40625 and parameters: {'batch_size': 16, 'learning_rate': 0.0004821417790136003, 'n_layers': 2, 'dropout': 0.2589280243821459, 'units': 306}. Best is trial 7 with value: 0.40625.\n",
      "[I 2024-12-06 09:43:49,924] Trial 8 finished with value: 0.375 and parameters: {'batch_size': 128, 'learning_rate': 9.16723940939446e-05, 'n_layers': 4, 'dropout': 0.26025856692642213, 'units': 97}. Best is trial 7 with value: 0.40625.\n",
      "[I 2024-12-06 09:44:22,593] Trial 9 finished with value: 0.4000000059604645 and parameters: {'batch_size': 64, 'learning_rate': 0.00018848604658688935, 'n_layers': 2, 'dropout': 0.2515256975024802, 'units': 482}. Best is trial 7 with value: 0.40625.\n",
      "[I 2024-12-06 09:44:39,054] Trial 10 finished with value: 0.36250001192092896 and parameters: {'batch_size': 16, 'learning_rate': 0.001299705578703464, 'n_layers': 3, 'dropout': 0.3407444022302771, 'units': 224}. Best is trial 7 with value: 0.40625.\n",
      "[I 2024-12-06 09:44:55,287] Trial 11 finished with value: 0.32499998807907104 and parameters: {'batch_size': 32, 'learning_rate': 3.312270636842417e-05, 'n_layers': 3, 'dropout': 0.2073961275740466, 'units': 373}. Best is trial 7 with value: 0.40625.\n",
      "[I 2024-12-06 09:45:05,729] Trial 12 finished with value: 0.39375001192092896 and parameters: {'batch_size': 64, 'learning_rate': 0.0007659375040993204, 'n_layers': 2, 'dropout': 0.21044020505377498, 'units': 509}. Best is trial 7 with value: 0.40625.\n",
      "[I 2024-12-06 09:45:19,694] Trial 13 finished with value: 0.40625 and parameters: {'batch_size': 16, 'learning_rate': 0.00047487703770570294, 'n_layers': 2, 'dropout': 0.3269706718559861, 'units': 309}. Best is trial 7 with value: 0.40625.\n",
      "[I 2024-12-06 09:45:29,845] Trial 14 finished with value: 0.3499999940395355 and parameters: {'batch_size': 16, 'learning_rate': 0.0023443182587383703, 'n_layers': 3, 'dropout': 0.33391671459666095, 'units': 313}. Best is trial 7 with value: 0.40625.\n",
      "[I 2024-12-06 09:45:40,182] Trial 15 finished with value: 0.375 and parameters: {'batch_size': 16, 'learning_rate': 0.0005306423325950929, 'n_layers': 2, 'dropout': 0.47113773772493167, 'units': 197}. Best is trial 7 with value: 0.40625.\n",
      "[I 2024-12-06 09:45:52,674] Trial 16 finished with value: 0.35624998807907104 and parameters: {'batch_size': 16, 'learning_rate': 0.002554028546570054, 'n_layers': 4, 'dropout': 0.3827224777417711, 'units': 40}. Best is trial 7 with value: 0.40625.\n",
      "[I 2024-12-06 09:45:59,910] Trial 17 finished with value: 0.24375000596046448 and parameters: {'batch_size': 32, 'learning_rate': 6.123673437227589e-05, 'n_layers': 3, 'dropout': 0.19324932132566952, 'units': 411}. Best is trial 7 with value: 0.40625.\n",
      "[I 2024-12-06 09:46:10,886] Trial 18 finished with value: 0.41874998807907104 and parameters: {'batch_size': 16, 'learning_rate': 0.00038703786165321136, 'n_layers': 2, 'dropout': 0.3121062182951967, 'units': 284}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:46:21,406] Trial 19 finished with value: 0.3499999940395355 and parameters: {'batch_size': 16, 'learning_rate': 0.0003451505171459006, 'n_layers': 3, 'dropout': 0.30580608091049527, 'units': 270}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:46:27,403] Trial 20 finished with value: 0.3812499940395355 and parameters: {'batch_size': 16, 'learning_rate': 0.002006617503710044, 'n_layers': 2, 'dropout': 0.3856194285992285, 'units': 198}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:46:38,479] Trial 21 finished with value: 0.36250001192092896 and parameters: {'batch_size': 16, 'learning_rate': 0.0004286889795593691, 'n_layers': 2, 'dropout': 0.301734106493858, 'units': 310}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:46:45,801] Trial 22 finished with value: 0.36250001192092896 and parameters: {'batch_size': 16, 'learning_rate': 0.0006914850139573965, 'n_layers': 2, 'dropout': 0.34354374384983344, 'units': 351}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:47:00,280] Trial 23 finished with value: 0.40625 and parameters: {'batch_size': 16, 'learning_rate': 0.0003214240873786849, 'n_layers': 2, 'dropout': 0.24415063945216578, 'units': 287}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:47:06,625] Trial 24 finished with value: 0.2750000059604645 and parameters: {'batch_size': 32, 'learning_rate': 9.128547814656896e-05, 'n_layers': 3, 'dropout': 0.29376850964554185, 'units': 249}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:47:14,610] Trial 25 finished with value: 0.4000000059604645 and parameters: {'batch_size': 16, 'learning_rate': 0.001264311043165149, 'n_layers': 2, 'dropout': 0.1756063445392835, 'units': 404}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:47:23,026] Trial 26 finished with value: 0.3687500059604645 and parameters: {'batch_size': 16, 'learning_rate': 0.004043102348435575, 'n_layers': 3, 'dropout': 0.368531945506853, 'units': 183}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:47:31,993] Trial 27 finished with value: 0.35624998807907104 and parameters: {'batch_size': 16, 'learning_rate': 0.001157820956456486, 'n_layers': 2, 'dropout': 0.42091853699735937, 'units': 286}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:47:44,967] Trial 28 finished with value: 0.3375000059604645 and parameters: {'batch_size': 16, 'learning_rate': 0.0002772203381449531, 'n_layers': 4, 'dropout': 0.28711724672449745, 'units': 361}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:47:57,522] Trial 29 finished with value: 0.4124999940395355 and parameters: {'batch_size': 32, 'learning_rate': 9.33427869580357e-05, 'n_layers': 2, 'dropout': 0.32639539744799906, 'units': 432}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:48:11,006] Trial 30 finished with value: 0.3812499940395355 and parameters: {'batch_size': 32, 'learning_rate': 1.7398959974983778e-05, 'n_layers': 2, 'dropout': 0.2297687080983351, 'units': 444}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:48:18,592] Trial 31 finished with value: 0.3062500059604645 and parameters: {'batch_size': 32, 'learning_rate': 8.284412935209621e-05, 'n_layers': 2, 'dropout': 0.3276940713672899, 'units': 439}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:48:29,057] Trial 32 finished with value: 0.4000000059604645 and parameters: {'batch_size': 32, 'learning_rate': 0.00012464004202348078, 'n_layers': 2, 'dropout': 0.3621611143879533, 'units': 329}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:48:33,956] Trial 33 finished with value: 0.3062500059604645 and parameters: {'batch_size': 32, 'learning_rate': 4.148704762977279e-05, 'n_layers': 2, 'dropout': 0.4113214668953214, 'units': 235}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:48:42,164] Trial 34 finished with value: 0.40625 and parameters: {'batch_size': 64, 'learning_rate': 0.00023313387307009412, 'n_layers': 2, 'dropout': 0.2693520492445946, 'units': 314}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:48:50,220] Trial 35 finished with value: 0.39375001192092896 and parameters: {'batch_size': 128, 'learning_rate': 0.0005195551970267197, 'n_layers': 2, 'dropout': 0.32334082019657584, 'units': 389}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:49:02,398] Trial 36 finished with value: 0.39375001192092896 and parameters: {'batch_size': 16, 'learning_rate': 0.00014831673305886693, 'n_layers': 5, 'dropout': 0.2785339733228872, 'units': 153}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:49:11,065] Trial 37 finished with value: 0.38749998807907104 and parameters: {'batch_size': 128, 'learning_rate': 0.00046465044441115007, 'n_layers': 3, 'dropout': 0.31042789954388644, 'units': 437}. Best is trial 18 with value: 0.41874998807907104.\n",
      "[I 2024-12-06 09:49:24,668] Trial 38 finished with value: 0.42500001192092896 and parameters: {'batch_size': 32, 'learning_rate': 0.00022674864075169333, 'n_layers': 2, 'dropout': 0.15973277677538483, 'units': 336}. Best is trial 38 with value: 0.42500001192092896.\n",
      "[I 2024-12-06 09:49:35,860] Trial 39 finished with value: 0.38749998807907104 and parameters: {'batch_size': 32, 'learning_rate': 5.137945411730265e-05, 'n_layers': 2, 'dropout': 0.10038381977015859, 'units': 380}. Best is trial 38 with value: 0.42500001192092896.\n",
      "[I 2024-12-06 09:49:43,251] Trial 40 finished with value: 0.34375 and parameters: {'batch_size': 32, 'learning_rate': 2.5443728479108606e-05, 'n_layers': 3, 'dropout': 0.1442868748810072, 'units': 355}. Best is trial 38 with value: 0.42500001192092896.\n",
      "[I 2024-12-06 09:49:56,542] Trial 41 finished with value: 0.4312500059604645 and parameters: {'batch_size': 32, 'learning_rate': 0.00021842541114178705, 'n_layers': 2, 'dropout': 0.1518812157082038, 'units': 335}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:50:07,193] Trial 42 finished with value: 0.4124999940395355 and parameters: {'batch_size': 32, 'learning_rate': 0.00013405322631282563, 'n_layers': 2, 'dropout': 0.15558614482709832, 'units': 342}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:50:19,256] Trial 43 finished with value: 0.4312500059604645 and parameters: {'batch_size': 32, 'learning_rate': 0.00011933390743020468, 'n_layers': 2, 'dropout': 0.15803350541369865, 'units': 332}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:50:26,338] Trial 44 finished with value: 0.40625 and parameters: {'batch_size': 32, 'learning_rate': 0.0002049587395307686, 'n_layers': 2, 'dropout': 0.12779917434897972, 'units': 286}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:50:36,209] Trial 45 finished with value: 0.41874998807907104 and parameters: {'batch_size': 32, 'learning_rate': 0.00010854958534691876, 'n_layers': 2, 'dropout': 0.1741001489772099, 'units': 459}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:50:46,465] Trial 46 finished with value: 0.42500001192092896 and parameters: {'batch_size': 32, 'learning_rate': 0.0002514035521712037, 'n_layers': 2, 'dropout': 0.1748731204243534, 'units': 473}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:50:58,652] Trial 47 finished with value: 0.40625 and parameters: {'batch_size': 32, 'learning_rate': 0.00027589150110379366, 'n_layers': 3, 'dropout': 0.14932667983877554, 'units': 262}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:51:11,412] Trial 48 finished with value: 0.42500001192092896 and parameters: {'batch_size': 32, 'learning_rate': 6.779095740282327e-05, 'n_layers': 2, 'dropout': 0.11656733745707074, 'units': 494}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:51:18,695] Trial 49 finished with value: 0.40625 and parameters: {'batch_size': 32, 'learning_rate': 0.00016129591864692157, 'n_layers': 2, 'dropout': 0.11959319919412241, 'units': 467}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:51:26,240] Trial 50 finished with value: 0.3187499940395355 and parameters: {'batch_size': 32, 'learning_rate': 6.68683280138055e-05, 'n_layers': 5, 'dropout': 0.17073364056824492, 'units': 510}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:51:34,448] Trial 51 finished with value: 0.39375001192092896 and parameters: {'batch_size': 32, 'learning_rate': 0.00021128370629451605, 'n_layers': 2, 'dropout': 0.19512376465116463, 'units': 483}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:51:46,111] Trial 52 finished with value: 0.41874998807907104 and parameters: {'batch_size': 32, 'learning_rate': 0.00017189706049327641, 'n_layers': 2, 'dropout': 0.1403046623561882, 'units': 327}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:51:53,127] Trial 53 finished with value: 0.4000000059604645 and parameters: {'batch_size': 64, 'learning_rate': 0.000345049845539909, 'n_layers': 2, 'dropout': 0.11245983678558175, 'units': 415}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:52:01,607] Trial 54 finished with value: 0.4124999940395355 and parameters: {'batch_size': 32, 'learning_rate': 0.0006556323558491102, 'n_layers': 2, 'dropout': 0.15854979055429724, 'units': 506}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:52:10,597] Trial 55 finished with value: 0.3687500059604645 and parameters: {'batch_size': 128, 'learning_rate': 6.637700596309783e-05, 'n_layers': 2, 'dropout': 0.23123020847902803, 'units': 373}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:52:16,645] Trial 56 finished with value: 0.39375001192092896 and parameters: {'batch_size': 32, 'learning_rate': 0.0002488766451767761, 'n_layers': 2, 'dropout': 0.1907256514042758, 'units': 92}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:52:29,408] Trial 57 finished with value: 0.4312500059604645 and parameters: {'batch_size': 32, 'learning_rate': 0.0001211350466116734, 'n_layers': 3, 'dropout': 0.1326158575191067, 'units': 298}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:52:44,268] Trial 58 finished with value: 0.4312500059604645 and parameters: {'batch_size': 32, 'learning_rate': 3.106011967255643e-05, 'n_layers': 4, 'dropout': 0.1319338595349118, 'units': 491}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:52:50,577] Trial 59 finished with value: 0.23749999701976776 and parameters: {'batch_size': 32, 'learning_rate': 1.252015468159264e-05, 'n_layers': 4, 'dropout': 0.1312113535998065, 'units': 420}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:52:57,291] Trial 60 finished with value: 0.33125001192092896 and parameters: {'batch_size': 32, 'learning_rate': 2.8299794297025882e-05, 'n_layers': 4, 'dropout': 0.21064756899420006, 'units': 390}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:53:11,226] Trial 61 finished with value: 0.33125001192092896 and parameters: {'batch_size': 32, 'learning_rate': 3.955712544207903e-05, 'n_layers': 4, 'dropout': 0.16628736527456844, 'units': 490}. Best is trial 41 with value: 0.4312500059604645.\n",
      "[I 2024-12-06 09:53:23,064] Trial 62 finished with value: 0.4375 and parameters: {'batch_size': 32, 'learning_rate': 0.00011762471200990638, 'n_layers': 4, 'dropout': 0.13528652695817875, 'units': 460}. Best is trial 62 with value: 0.4375.\n",
      "[I 2024-12-06 09:53:29,526] Trial 63 finished with value: 0.3062500059604645 and parameters: {'batch_size': 32, 'learning_rate': 0.00012376774227362483, 'n_layers': 4, 'dropout': 0.12993090305452612, 'units': 465}. Best is trial 62 with value: 0.4375.\n",
      "[I 2024-12-06 09:53:41,944] Trial 64 finished with value: 0.39375001192092896 and parameters: {'batch_size': 32, 'learning_rate': 0.00010377262787725005, 'n_layers': 4, 'dropout': 0.18513864991062629, 'units': 298}. Best is trial 62 with value: 0.4375.\n",
      "[I 2024-12-06 09:53:50,910] Trial 65 finished with value: 0.40625 and parameters: {'batch_size': 32, 'learning_rate': 0.00016840417589017825, 'n_layers': 4, 'dropout': 0.143517962629447, 'units': 368}. Best is trial 62 with value: 0.4375.\n",
      "[I 2024-12-06 09:53:59,119] Trial 66 finished with value: 0.38749998807907104 and parameters: {'batch_size': 64, 'learning_rate': 0.009276590936874522, 'n_layers': 4, 'dropout': 0.15883343147733137, 'units': 458}. Best is trial 62 with value: 0.4375.\n",
      "[I 2024-12-06 09:54:09,760] Trial 67 finished with value: 0.4437499940395355 and parameters: {'batch_size': 32, 'learning_rate': 0.0003829039604703718, 'n_layers': 3, 'dropout': 0.1010772235117992, 'units': 320}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:54:21,852] Trial 68 finished with value: 0.4375 and parameters: {'batch_size': 32, 'learning_rate': 1.947937804120372e-05, 'n_layers': 3, 'dropout': 0.10354342338697894, 'units': 340}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:54:27,406] Trial 69 finished with value: 0.2562499940395355 and parameters: {'batch_size': 32, 'learning_rate': 1.850796263356257e-05, 'n_layers': 3, 'dropout': 0.10709535557039628, 'units': 347}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:54:33,692] Trial 70 finished with value: 0.24375000596046448 and parameters: {'batch_size': 32, 'learning_rate': 1.0764810270889701e-05, 'n_layers': 3, 'dropout': 0.10216207422012144, 'units': 318}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:54:42,754] Trial 71 finished with value: 0.38749998807907104 and parameters: {'batch_size': 32, 'learning_rate': 1.4484172648266196e-05, 'n_layers': 3, 'dropout': 0.13433993387933726, 'units': 298}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:54:54,757] Trial 72 finished with value: 0.39375001192092896 and parameters: {'batch_size': 32, 'learning_rate': 2.2121064571745487e-05, 'n_layers': 3, 'dropout': 0.1245894711188976, 'units': 336}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:54:59,847] Trial 73 finished with value: 0.3187499940395355 and parameters: {'batch_size': 32, 'learning_rate': 4.114154424071802e-05, 'n_layers': 3, 'dropout': 0.11312903101867522, 'units': 246}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:55:12,383] Trial 74 finished with value: 0.32499998807907104 and parameters: {'batch_size': 32, 'learning_rate': 5.236805040336852e-05, 'n_layers': 4, 'dropout': 0.14397796832448811, 'units': 272}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:55:18,250] Trial 75 finished with value: 0.3812499940395355 and parameters: {'batch_size': 128, 'learning_rate': 8.204600638527095e-05, 'n_layers': 3, 'dropout': 0.4871901023031084, 'units': 322}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:55:25,505] Trial 76 finished with value: 0.3499999940395355 and parameters: {'batch_size': 32, 'learning_rate': 0.0003930068926092943, 'n_layers': 3, 'dropout': 0.11922218201091478, 'units': 300}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:55:34,077] Trial 77 finished with value: 0.3812499940395355 and parameters: {'batch_size': 32, 'learning_rate': 0.0008847073027329556, 'n_layers': 4, 'dropout': 0.15166354400989968, 'units': 356}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:55:39,538] Trial 78 finished with value: 0.3187499940395355 and parameters: {'batch_size': 64, 'learning_rate': 0.00031138411374267153, 'n_layers': 3, 'dropout': 0.1371344414222333, 'units': 272}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:55:45,703] Trial 79 finished with value: 0.3062500059604645 and parameters: {'batch_size': 32, 'learning_rate': 3.135271437425575e-05, 'n_layers': 4, 'dropout': 0.20262743143369605, 'units': 336}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:55:56,716] Trial 80 finished with value: 0.375 and parameters: {'batch_size': 32, 'learning_rate': 0.0001394128872015423, 'n_layers': 5, 'dropout': 0.1635121188388459, 'units': 227}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:56:02,860] Trial 81 finished with value: 0.3687500059604645 and parameters: {'batch_size': 32, 'learning_rate': 0.0005811837322462858, 'n_layers': 3, 'dropout': 0.17842735441795354, 'units': 448}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:56:10,231] Trial 82 finished with value: 0.41874998807907104 and parameters: {'batch_size': 32, 'learning_rate': 0.00019944103707513343, 'n_layers': 3, 'dropout': 0.12523889136757013, 'units': 475}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:56:18,703] Trial 83 finished with value: 0.3812499940395355 and parameters: {'batch_size': 32, 'learning_rate': 0.0002410083590852762, 'n_layers': 4, 'dropout': 0.10985951627884097, 'units': 396}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:56:24,582] Trial 84 finished with value: 0.3812499940395355 and parameters: {'batch_size': 32, 'learning_rate': 0.0004033762525649002, 'n_layers': 3, 'dropout': 0.15238764674436747, 'units': 362}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:56:35,855] Trial 85 finished with value: 0.4312500059604645 and parameters: {'batch_size': 32, 'learning_rate': 0.00011708014489872756, 'n_layers': 2, 'dropout': 0.16865716447580373, 'units': 422}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:56:47,768] Trial 86 finished with value: 0.40625 and parameters: {'batch_size': 32, 'learning_rate': 0.00011088198879081507, 'n_layers': 3, 'dropout': 0.10092285236672553, 'units': 381}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:56:54,998] Trial 87 finished with value: 0.36250001192092896 and parameters: {'batch_size': 32, 'learning_rate': 8.618671687668699e-05, 'n_layers': 4, 'dropout': 0.1372620211598297, 'units': 311}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:57:01,588] Trial 88 finished with value: 0.38749998807907104 and parameters: {'batch_size': 128, 'learning_rate': 0.0001412546438849692, 'n_layers': 2, 'dropout': 0.16591975396111722, 'units': 424}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:57:08,125] Trial 89 finished with value: 0.29374998807907104 and parameters: {'batch_size': 32, 'learning_rate': 5.496130829977233e-05, 'n_layers': 5, 'dropout': 0.12095971550303236, 'units': 347}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:57:14,902] Trial 90 finished with value: 0.4437499940395355 and parameters: {'batch_size': 32, 'learning_rate': 0.0001854197598066036, 'n_layers': 2, 'dropout': 0.18391236621388302, 'units': 406}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:57:21,620] Trial 91 finished with value: 0.4437499940395355 and parameters: {'batch_size': 32, 'learning_rate': 0.0001815075686790736, 'n_layers': 2, 'dropout': 0.21975145506805835, 'units': 411}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:57:32,660] Trial 92 finished with value: 0.41874998807907104 and parameters: {'batch_size': 32, 'learning_rate': 0.0003053272709709674, 'n_layers': 2, 'dropout': 0.22258926327321663, 'units': 410}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:57:43,988] Trial 93 finished with value: 0.41874998807907104 and parameters: {'batch_size': 32, 'learning_rate': 7.479616553415882e-05, 'n_layers': 2, 'dropout': 0.18395827627962658, 'units': 429}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:57:50,920] Trial 94 finished with value: 0.4124999940395355 and parameters: {'batch_size': 32, 'learning_rate': 0.00018329250598852242, 'n_layers': 2, 'dropout': 0.14933550641316717, 'units': 401}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:58:05,927] Trial 95 finished with value: 0.4312500059604645 and parameters: {'batch_size': 32, 'learning_rate': 0.00011683284596081543, 'n_layers': 2, 'dropout': 0.20354563450573282, 'units': 497}. Best is trial 67 with value: 0.4437499940395355.\n",
      "[I 2024-12-06 09:58:13,916] Trial 96 finished with value: 0.44999998807907104 and parameters: {'batch_size': 32, 'learning_rate': 0.00010069229805765904, 'n_layers': 2, 'dropout': 0.18428679794249464, 'units': 442}. Best is trial 96 with value: 0.44999998807907104.\n",
      "[I 2024-12-06 09:58:23,638] Trial 97 finished with value: 0.4437499940395355 and parameters: {'batch_size': 64, 'learning_rate': 0.00015038733575246005, 'n_layers': 2, 'dropout': 0.19643102027227125, 'units': 439}. Best is trial 96 with value: 0.44999998807907104.\n",
      "[I 2024-12-06 09:58:33,395] Trial 98 finished with value: 0.41874998807907104 and parameters: {'batch_size': 64, 'learning_rate': 0.00014486796761227475, 'n_layers': 2, 'dropout': 0.21404041161508341, 'units': 443}. Best is trial 96 with value: 0.44999998807907104.\n",
      "[I 2024-12-06 09:58:39,796] Trial 99 finished with value: 0.39375001192092896 and parameters: {'batch_size': 64, 'learning_rate': 9.686976886538854e-05, 'n_layers': 2, 'dropout': 0.2463672631432593, 'units': 451}. Best is trial 96 with value: 0.44999998807907104.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mejores hiperparámetros encontrados:\n",
      "{'batch_size': 32, 'learning_rate': 0.00010069229805765904, 'n_layers': 2, 'dropout': 0.18428679794249464, 'units': 442}\n",
      "\n",
      "Mejor accuracy: 0.4500\n",
      "\n",
      "Entrenando modelo final...\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 30ms/step - accuracy: 0.3025 - loss: 2.0346 - val_accuracy: 0.3063 - val_loss: 1.6157\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2750 - loss: 2.1018 - val_accuracy: 0.3000 - val_loss: 1.3749\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2914 - loss: 1.8666 - val_accuracy: 0.2438 - val_loss: 1.3905\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3458 - loss: 1.7463 - val_accuracy: 0.2625 - val_loss: 1.4617\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2985 - loss: 1.7598 - val_accuracy: 0.2500 - val_loss: 1.4637\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.2836 - loss: 1.7735 - val_accuracy: 0.2500 - val_loss: 1.4631\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2991 - loss: 1.6839 - val_accuracy: 0.2438 - val_loss: 1.4432\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2794 - loss: 1.7030 - val_accuracy: 0.2625 - val_loss: 1.4506\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2273 - loss: 1.7732 - val_accuracy: 0.2750 - val_loss: 1.4465\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2726 - loss: 1.6738 - val_accuracy: 0.2625 - val_loss: 1.4366\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2899 - loss: 1.7108 - val_accuracy: 0.2500 - val_loss: 1.4335\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3280 - loss: 1.6179 - val_accuracy: 0.2937 - val_loss: 1.4256\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.2884 - loss: 1.6903 - val_accuracy: 0.3063 - val_loss: 1.3866\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3098 - loss: 1.6859 - val_accuracy: 0.2812 - val_loss: 1.3822\n",
      "Epoch 15/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2866 - loss: 1.6071 - val_accuracy: 0.3375 - val_loss: 1.3759\n",
      "Epoch 16/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3096 - loss: 1.6681 - val_accuracy: 0.2625 - val_loss: 1.3848\n",
      "Epoch 17/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.3178 - loss: 1.6558 - val_accuracy: 0.2812 - val_loss: 1.3877\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
      "\n",
      "Reporte de clasificación final:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.02      0.03        60\n",
      "           1       0.27      0.46      0.34        39\n",
      "           2       0.38      0.05      0.10        55\n",
      "           3       0.22      0.57      0.32        46\n",
      "\n",
      "    accuracy                           0.24       200\n",
      "   macro avg       0.25      0.27      0.20       200\n",
      "weighted avg       0.25      0.24      0.17       200\n",
      "\n",
      "\n",
      "Resultados guardados en: ../models/results_20241206_095839.pkl\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report\n",
    "import datetime\n",
    "\n",
    "def prepare_data():\n",
    "    try:\n",
    "        # Cargar datos\n",
    "        df = pd.read_csv('../data/proc_escalado.csv')\n",
    "        print(f\"Dimensiones del dataset: {df.shape}\")\n",
    "\n",
    "        # Identificar columnas no numéricas\n",
    "        object_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "        # Convertir columnas object a numéricas\n",
    "        le = LabelEncoder()\n",
    "        for col in object_columns:\n",
    "            df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "        # Verificar que todas las columnas sean numéricas\n",
    "        assert df.select_dtypes(include=['object']).empty, \"Aún hay columnas no numéricas\"\n",
    "\n",
    "        # Separar features y target\n",
    "        X = df.drop('custcat', axis=1)\n",
    "        y = df['custcat'] - 1\n",
    "\n",
    "        # Convertir a numpy arrays\n",
    "        X = X.values.astype('float32')\n",
    "        y = y.values.astype('int32')\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error en prepare_data: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def create_model(trial, input_shape):\n",
    "    # Hiperparámetros\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "    n_layers = trial.suggest_int('n_layers', 2, 5)\n",
    "    dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
    "    units = trial.suggest_int('units', 32, 512)\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Primera capa\n",
    "    model.add(Dense(units, activation='relu', input_shape=(input_shape,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(dropout))\n",
    "\n",
    "    # Capas ocultas\n",
    "    for i in range(n_layers):\n",
    "        units = units // 2\n",
    "        if units < 32:\n",
    "            units = 32\n",
    "        model.add(Dense(units, activation='relu'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Dropout(dropout))\n",
    "\n",
    "    # Capa de salida\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def objective(trial):\n",
    "    try:\n",
    "        # Hiperparámetros\n",
    "        batch_size = trial.suggest_categorical('batch_size', [16, 32, 64, 128])\n",
    "\n",
    "        # Crear modelo\n",
    "        model = create_model(trial, X_train.shape[1])\n",
    "\n",
    "        # Entrenar\n",
    "        history = model.fit(\n",
    "            X_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=50,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
    "            verbose=0\n",
    "        )\n",
    "\n",
    "        return max(history.history['val_accuracy'])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error en objective: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "# Crear directorio para modelos\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "\n",
    "# Cargar y preparar datos\n",
    "print(\"Cargando y preparando datos...\")\n",
    "X, y = prepare_data()\n",
    "\n",
    "# Split de datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Optimización con Optuna\n",
    "print(\"Iniciando optimización con Optuna...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100, timeout=7200)\n",
    "\n",
    "print(\"\\nMejores hiperparámetros encontrados:\")\n",
    "print(study.best_params)\n",
    "print(f\"\\nMejor accuracy: {study.best_value:.4f}\")\n",
    "\n",
    "# Entrenar modelo final con los mejores hiperparámetros\n",
    "print(\"\\nEntrenando modelo final...\")\n",
    "final_model = create_model(study.best_trial, X_train.shape[1])\n",
    "\n",
    "# Timestamp para los archivos\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "# Callbacks para el modelo final\n",
    "final_callbacks = [\n",
    "    EarlyStopping(patience=15, restore_best_weights=True),\n",
    "    ModelCheckpoint(\n",
    "        filepath=f'models/best_model_{timestamp}.keras',\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy'\n",
    "    )\n",
    "]\n",
    "\n",
    "# Entrenar modelo final\n",
    "history = final_model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=study.best_params['batch_size'],\n",
    "    epochs=100,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=final_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Guardar modelo final\n",
    "final_model.save(f'../models/final_model_{timestamp}.keras')\n",
    "\n",
    "# Evaluar modelo final\n",
    "y_pred = np.argmax(final_model.predict(X_test), axis=1)\n",
    "print(\"\\nReporte de clasificación final:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Guardar resultados\n",
    "results = {\n",
    "    'best_params': study.best_params,\n",
    "    'best_value': study.best_value,\n",
    "    'history': history.history,\n",
    "    'classification_report': classification_report(y_test, y_pred, output_dict=True)\n",
    "}\n",
    "\n",
    "pd.to_pickle(results, f'../models/results_{timestamp}.pkl')\n",
    "print(f\"\\nResultados guardados en: ../models/results_{timestamp}.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
